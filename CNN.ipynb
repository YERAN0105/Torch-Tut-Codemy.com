{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST Images - Deep Learning with PyTorch 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link: https://www.tensorflow.org/datasets/catalog/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MNIST image files into Tensor of 4-Dimentions (# of images, Height, Width, Color Channel)\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Data\n",
    "train_data = datasets.MNIST(root=\"cnn_data\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "test_data = datasets.MNIST(root=\"cnn_data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: cnn_data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show what directory we are currently in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Learning\\\\Torch-Tut-Codemy.com'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 42B4-CB90\n",
      "\n",
      " Directory of c:\\Learning\\Torch-Tut-Codemy.com\n",
      "\n",
      "09/21/2024  08:46 PM    <DIR>          .\n",
      "09/22/2024  09:19 AM    <DIR>          ..\n",
      "09/19/2024  03:18 PM    <DIR>          .idea\n",
      "09/20/2024  11:37 AM            53,837 59954intro_to_CNN.jfif\n",
      "09/03/2024  11:23 AM             4,551 bezdekIris.data\n",
      "09/23/2024  09:35 AM            15,488 CNN.ipynb\n",
      "09/21/2024  08:46 PM    <DIR>          cnn_data\n",
      "09/21/2024  07:46 PM             3,680 CNN_Intro.ipynb\n",
      "09/20/2024  12:00 PM            79,414 convolutional-layer.jpg\n",
      "09/20/2024  11:48 AM            15,114 image.png\n",
      "09/03/2024  11:23 AM               105 Index\n",
      "09/03/2024  11:23 AM             4,551 iris.data\n",
      "09/03/2024  11:23 AM             2,998 iris.names\n",
      "09/20/2024  12:34 PM            48,869 locally_connected.png\n",
      "09/20/2024  11:04 AM             3,136 my_iris_torch_model.pt\n",
      "09/20/2024  11:15 AM            49,716 Part-1-SimpleNN.ipynb\n",
      "09/21/2024  07:37 PM           168,629 pooling.png\n",
      "              13 File(s)        450,088 bytes\n",
      "               4 Dir(s)  298,386,669,568 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional and Pooling Layers - Deep Learning with PyTorch 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete a small batch for images.....let's say 10\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN model\n",
    "# Describe Convolutional layer and what it's doing (2 convolutional layers)\n",
    "# This is just an example in the step we'll build out the actual model\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 1 MNIST record/image\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above output tells that there is one image with 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a 4D batch\n",
    "x = X_train.view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform our first convolutional \n",
    "x = F.relu(conv1(x)) #Rectified Linear Unit for our activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 26, 26])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 single image, 6 is the filters/kernels we asked for, 26x26(Since we didn't add any padding to the conv layer it will remove some pixels from the image border)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass thru the pooling layer\n",
    "x = F.max_pool2d(x, 2,2) # kernel of 2 and stride of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](output_after_pool_eq.png \"Equation to calculate the output size after the pooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((26-2) / 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 13, 13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # ((26-2) / 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do our 2nd convolutional layer\n",
    "x = F.relu(conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 11, 11])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd pooling layer\n",
    "x = F.max_pool2d(x, 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # ((11-2) / 2) + 1 = 5.5 but we have to round down, because you can't invent data to round up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explaining what happened to the pixels over time\n",
    "((28-2)/2 - 2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model - Deep Learning with PyTorch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(5*5*16, 120) #Here the input is the shape of the output tensor which we tested for one image earlier\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10) # Here the output should be 10 because there are 10 classes in this dataset, for other input and output values we can play around(but everytime you go down the neurons should be decreased)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2,2)\n",
    "        # Second Pass\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2,2)\n",
    "\n",
    "        # Re-View to flattern it out\n",
    "        X = X.view(-1, 5*5*16) #negative one so that we can vary the batch size\n",
    "        \n",
    "        #Fully connected layer\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the model\n",
    "torch.manual_seed(41)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # smaller the learning rate, the longer its gonna take to train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test CNN Model - Deep Learning with PyTorch 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 600 Loss: 1.3900482654571533\n",
      "Epoch: 0 Batch: 1200 Loss: 1.1512937545776367\n",
      "Epoch: 0 Batch: 1800 Loss: 0.9217565655708313\n",
      "Epoch: 0 Batch: 2400 Loss: 1.1531751155853271\n",
      "Epoch: 0 Batch: 3000 Loss: 0.9219411015510559\n",
      "Epoch: 0 Batch: 3600 Loss: 0.7013807892799377\n",
      "Epoch: 0 Batch: 4200 Loss: 0.9213376045227051\n",
      "Epoch: 0 Batch: 4800 Loss: 0.2304559201002121\n",
      "Epoch: 0 Batch: 5400 Loss: 0.9210673570632935\n",
      "Epoch: 0 Batch: 6000 Loss: 0.9219022989273071\n",
      "Epoch: 1 Batch: 600 Loss: 0.9210359454154968\n",
      "Epoch: 1 Batch: 1200 Loss: 0.9235343933105469\n",
      "Epoch: 1 Batch: 1800 Loss: 1.1513195037841797\n",
      "Epoch: 1 Batch: 2400 Loss: 1.3815526962280273\n",
      "Epoch: 1 Batch: 3000 Loss: 0.9215022921562195\n",
      "Epoch: 1 Batch: 3600 Loss: 1.1531686782836914\n",
      "Epoch: 1 Batch: 4200 Loss: 1.1516876220703125\n",
      "Epoch: 1 Batch: 4800 Loss: 0.9210476875305176\n",
      "Epoch: 1 Batch: 5400 Loss: 0.9157994985580444\n",
      "Epoch: 1 Batch: 6000 Loss: 2.879031181335449\n",
      "Epoch: 2 Batch: 600 Loss: 0.9216534495353699\n",
      "Epoch: 2 Batch: 1200 Loss: 0.9210355877876282\n",
      "Epoch: 2 Batch: 1800 Loss: 1.381553053855896\n",
      "Epoch: 2 Batch: 2400 Loss: 1.3819653987884521\n",
      "Epoch: 2 Batch: 3000 Loss: 0.46104708313941956\n",
      "Epoch: 2 Batch: 3600 Loss: 1.3816578388214111\n",
      "Epoch: 2 Batch: 4200 Loss: 0.9216005206108093\n",
      "Epoch: 2 Batch: 4800 Loss: 0.9211519956588745\n",
      "Epoch: 2 Batch: 5400 Loss: 1.611941933631897\n",
      "Epoch: 2 Batch: 6000 Loss: 1.3816457986831665\n",
      "Epoch: 3 Batch: 600 Loss: 1.8503177165985107\n",
      "Epoch: 3 Batch: 1200 Loss: 0.9210559129714966\n",
      "Epoch: 3 Batch: 1800 Loss: 1.151892900466919\n",
      "Epoch: 3 Batch: 2400 Loss: 1.3815670013427734\n",
      "Epoch: 3 Batch: 3000 Loss: 1.1520841121673584\n",
      "Epoch: 3 Batch: 3600 Loss: 0.4614558219909668\n",
      "Epoch: 3 Batch: 4200 Loss: 0.6984196901321411\n",
      "Epoch: 3 Batch: 4800 Loss: 0.921212375164032\n",
      "Epoch: 3 Batch: 5400 Loss: 1.1518861055374146\n",
      "Epoch: 3 Batch: 6000 Loss: 1.151515007019043\n",
      "Epoch: 4 Batch: 600 Loss: 1.4781646728515625\n",
      "Epoch: 4 Batch: 1200 Loss: 0.4605231285095215\n",
      "Epoch: 4 Batch: 1800 Loss: 0.46054965257644653\n",
      "Epoch: 4 Batch: 2400 Loss: 1.0850228071212769\n",
      "Epoch: 4 Batch: 3000 Loss: 0.9210518002510071\n",
      "Epoch: 4 Batch: 3600 Loss: 1.1512928009033203\n",
      "Epoch: 4 Batch: 4200 Loss: 0.6909471750259399\n",
      "Epoch: 4 Batch: 4800 Loss: 0.8419002294540405\n",
      "Epoch: 4 Batch: 5400 Loss: 2.072326898574829\n",
      "Epoch: 4 Batch: 6000 Loss: 1.3815511465072632\n",
      "trainng time took 3.4327731649080913 miniutes!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# create variables to track things\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# For loop of Epochs\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    #Train\n",
    "    for b,(X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1 # Start our batch at 1\n",
    "        y_pred = model(X_train) #get predicted values from the training set. Not flattened 2D\n",
    "        loss = criterion(y_pred, y_train) #how off are we? Compare the predictions with y_train\n",
    "\n",
    "        predicted = torch.max(y_pred.data, 1)[1] # add up the number of correct predictions. Indexed off the first point \n",
    "        batch_corr = (predicted == y_train).sum() # how many we got correct from this batch. True = 1, False = 0 ,sum those up \n",
    "        trn_corr += batch_corr # keep track as we go along in training.\n",
    "\n",
    "        #update our parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print our results\n",
    "        if b%600 ==0:\n",
    "            print(f'Epoch: {i} Batch: {b} Loss: {loss.item()}')\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    #Test\n",
    "    with torch.no_grad(): # No gradientso we don't update weights and biases with test data\n",
    "        for b,(X_test, y_test) in enumerate(test_loader):\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val.data, 1)[1] #adding up correct predictions\n",
    "            tst_corr += (predicted == y_test).sum() # T=1 F=0 and sum away\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f'trainng time took {total/60} miniutes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tarining_loop_code.png\" alt=\"training loop code\" title=\"training loop code\" width=\"500\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop\n",
    "- Enumerate through batches: Iterates over the training data in batches using train_loader.\n",
    "- Model prediction: y_pred = model(X_train) computes the predictions for the current batch of data.\n",
    "- Calculate loss: The loss function (criterion) calculates how far off the model's predictions (y_pred) are from the true labels (y_train).\n",
    "- Correct Predictions:\n",
    "    - torch.max(y_pred.data, 1)[1] finds the predicted class labels.\n",
    "    - (predicted == y_train).sum() calculates how many predictions are correct.\n",
    "- Backpropagation and Optimizer Step:\n",
    "    - optimizer.zero_grad() clears previous gradients.\n",
    "    - loss.backward() computes gradients via backpropagation.\n",
    "    - optimizer.step() updates the model's parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"testing_loop_code.png\" alt=\"training loop code\" title=\"training loop code\" width=\"400\" height=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Loop (No Gradients)\n",
    "- In the testing loop, the model evaluates the test data without calculating gradients (torch.no_grad()), meaning no updates are made to the model.\n",
    "- For each batch of test data:\n",
    "    - y_val = model(X_test) gets the model's predictions.\n",
    "    - torch.max(y_val.data, 1)[1] finds the predicted class.\n",
    "    - (predicted == y_test).sum() counts how many predictions were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph CNN Results - Deep Learning with PyTorch 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
